{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import set_config\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>755</td>\n",
       "      <td>948</td>\n",
       "      <td>788</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530</td>\n",
       "      <td>214</td>\n",
       "      <td>536</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>436</td>\n",
       "      <td>58</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>736</td>\n",
       "      <td>89</td>\n",
       "      <td>920</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>340</td>\n",
       "      <td>57</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C    D\n",
       "0  755  948  788  364\n",
       "1  530  214  536  397\n",
       "2   79  436   58  330\n",
       "3  736   89  920   26\n",
       "4   49  340   57  932"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(np.random.randint(0,1000,size=(10000, 4)), columns=list('ABCD'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AxA</th>\n",
       "      <th>AxB</th>\n",
       "      <th>AxC</th>\n",
       "      <th>AxD</th>\n",
       "      <th>BxB</th>\n",
       "      <th>BxC</th>\n",
       "      <th>BxD</th>\n",
       "      <th>CxC</th>\n",
       "      <th>CxD</th>\n",
       "      <th>DxD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570025</td>\n",
       "      <td>715740</td>\n",
       "      <td>594940</td>\n",
       "      <td>274820</td>\n",
       "      <td>898704</td>\n",
       "      <td>747024</td>\n",
       "      <td>345072</td>\n",
       "      <td>620944</td>\n",
       "      <td>286832</td>\n",
       "      <td>132496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280900</td>\n",
       "      <td>113420</td>\n",
       "      <td>284080</td>\n",
       "      <td>210410</td>\n",
       "      <td>45796</td>\n",
       "      <td>114704</td>\n",
       "      <td>84958</td>\n",
       "      <td>287296</td>\n",
       "      <td>212792</td>\n",
       "      <td>157609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6241</td>\n",
       "      <td>34444</td>\n",
       "      <td>4582</td>\n",
       "      <td>26070</td>\n",
       "      <td>190096</td>\n",
       "      <td>25288</td>\n",
       "      <td>143880</td>\n",
       "      <td>3364</td>\n",
       "      <td>19140</td>\n",
       "      <td>108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>541696</td>\n",
       "      <td>65504</td>\n",
       "      <td>677120</td>\n",
       "      <td>19136</td>\n",
       "      <td>7921</td>\n",
       "      <td>81880</td>\n",
       "      <td>2314</td>\n",
       "      <td>846400</td>\n",
       "      <td>23920</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>16660</td>\n",
       "      <td>2793</td>\n",
       "      <td>45668</td>\n",
       "      <td>115600</td>\n",
       "      <td>19380</td>\n",
       "      <td>316880</td>\n",
       "      <td>3249</td>\n",
       "      <td>53124</td>\n",
       "      <td>868624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AxA     AxB     AxC     AxD     BxB     BxC     BxD     CxC     CxD  \\\n",
       "0  570025  715740  594940  274820  898704  747024  345072  620944  286832   \n",
       "1  280900  113420  284080  210410   45796  114704   84958  287296  212792   \n",
       "2    6241   34444    4582   26070  190096   25288  143880    3364   19140   \n",
       "3  541696   65504  677120   19136    7921   81880    2314  846400   23920   \n",
       "4    2401   16660    2793   45668  115600   19380  316880    3249   53124   \n",
       "\n",
       "      DxD  \n",
       "0  132496  \n",
       "1  157609  \n",
       "2  108900  \n",
       "3     676  \n",
       "4  868624  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "for idx1,col1 in enumerate(df.columns):\n",
    "    for idx2,col2 in enumerate(df.drop(columns=df.columns[:idx1]).columns):\n",
    "        df1[col1+'x'+col2] = df.loc[:,col1] * df.loc[:,col2]\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>AxA</th>\n",
       "      <th>AxB</th>\n",
       "      <th>AxC</th>\n",
       "      <th>AxD</th>\n",
       "      <th>BxB</th>\n",
       "      <th>BxC</th>\n",
       "      <th>BxD</th>\n",
       "      <th>CxC</th>\n",
       "      <th>CxD</th>\n",
       "      <th>DxD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>755</td>\n",
       "      <td>948</td>\n",
       "      <td>788</td>\n",
       "      <td>364</td>\n",
       "      <td>570025</td>\n",
       "      <td>715740</td>\n",
       "      <td>594940</td>\n",
       "      <td>274820</td>\n",
       "      <td>898704</td>\n",
       "      <td>747024</td>\n",
       "      <td>345072</td>\n",
       "      <td>620944</td>\n",
       "      <td>286832</td>\n",
       "      <td>132496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530</td>\n",
       "      <td>214</td>\n",
       "      <td>536</td>\n",
       "      <td>397</td>\n",
       "      <td>280900</td>\n",
       "      <td>113420</td>\n",
       "      <td>284080</td>\n",
       "      <td>210410</td>\n",
       "      <td>45796</td>\n",
       "      <td>114704</td>\n",
       "      <td>84958</td>\n",
       "      <td>287296</td>\n",
       "      <td>212792</td>\n",
       "      <td>157609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>436</td>\n",
       "      <td>58</td>\n",
       "      <td>330</td>\n",
       "      <td>6241</td>\n",
       "      <td>34444</td>\n",
       "      <td>4582</td>\n",
       "      <td>26070</td>\n",
       "      <td>190096</td>\n",
       "      <td>25288</td>\n",
       "      <td>143880</td>\n",
       "      <td>3364</td>\n",
       "      <td>19140</td>\n",
       "      <td>108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>736</td>\n",
       "      <td>89</td>\n",
       "      <td>920</td>\n",
       "      <td>26</td>\n",
       "      <td>541696</td>\n",
       "      <td>65504</td>\n",
       "      <td>677120</td>\n",
       "      <td>19136</td>\n",
       "      <td>7921</td>\n",
       "      <td>81880</td>\n",
       "      <td>2314</td>\n",
       "      <td>846400</td>\n",
       "      <td>23920</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>340</td>\n",
       "      <td>57</td>\n",
       "      <td>932</td>\n",
       "      <td>2401</td>\n",
       "      <td>16660</td>\n",
       "      <td>2793</td>\n",
       "      <td>45668</td>\n",
       "      <td>115600</td>\n",
       "      <td>19380</td>\n",
       "      <td>316880</td>\n",
       "      <td>3249</td>\n",
       "      <td>53124</td>\n",
       "      <td>868624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C    D     AxA     AxB     AxC     AxD     BxB     BxC     BxD  \\\n",
       "0  755  948  788  364  570025  715740  594940  274820  898704  747024  345072   \n",
       "1  530  214  536  397  280900  113420  284080  210410   45796  114704   84958   \n",
       "2   79  436   58  330    6241   34444    4582   26070  190096   25288  143880   \n",
       "3  736   89  920   26  541696   65504  677120   19136    7921   81880    2314   \n",
       "4   49  340   57  932    2401   16660    2793   45668  115600   19380  316880   \n",
       "\n",
       "      CxC     CxD     DxD  \n",
       "0  620944  286832  132496  \n",
       "1  287296  212792  157609  \n",
       "2    3364   19140  108900  \n",
       "3  846400   23920     676  \n",
       "4    3249   53124  868624  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.merge(df1, left_index=True, right_index=True)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_scal = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(index=df2.index, columns=df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df2.columns:\n",
    "    df3[col] = norm_scal.fit_transform(df2[col].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>AxA</th>\n",
       "      <th>AxB</th>\n",
       "      <th>AxC</th>\n",
       "      <th>AxD</th>\n",
       "      <th>BxB</th>\n",
       "      <th>BxC</th>\n",
       "      <th>BxD</th>\n",
       "      <th>CxC</th>\n",
       "      <th>CxD</th>\n",
       "      <th>DxD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.871354</td>\n",
       "      <td>1.539998</td>\n",
       "      <td>1.013701</td>\n",
       "      <td>-0.475045</td>\n",
       "      <td>0.780807</td>\n",
       "      <td>2.074419</td>\n",
       "      <td>1.571010</td>\n",
       "      <td>0.096039</td>\n",
       "      <td>1.880247</td>\n",
       "      <td>2.246063</td>\n",
       "      <td>0.422893</td>\n",
       "      <td>0.984923</td>\n",
       "      <td>0.177586</td>\n",
       "      <td>-0.675447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097133</td>\n",
       "      <td>-1.000501</td>\n",
       "      <td>0.144408</td>\n",
       "      <td>-0.361014</td>\n",
       "      <td>-0.184793</td>\n",
       "      <td>-0.625760</td>\n",
       "      <td>0.162509</td>\n",
       "      <td>-0.189062</td>\n",
       "      <td>-0.972482</td>\n",
       "      <td>-0.606603</td>\n",
       "      <td>-0.752361</td>\n",
       "      <td>-0.137652</td>\n",
       "      <td>-0.158191</td>\n",
       "      <td>-0.591777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.454749</td>\n",
       "      <td>-0.232121</td>\n",
       "      <td>-1.504488</td>\n",
       "      <td>-0.592531</td>\n",
       "      <td>-1.102080</td>\n",
       "      <td>-0.979806</td>\n",
       "      <td>-1.103892</td>\n",
       "      <td>-1.005014</td>\n",
       "      <td>-0.489840</td>\n",
       "      <td>-1.009996</td>\n",
       "      <td>-0.486138</td>\n",
       "      <td>-1.092955</td>\n",
       "      <td>-1.036416</td>\n",
       "      <td>-0.754062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.805975</td>\n",
       "      <td>-1.433147</td>\n",
       "      <td>1.469045</td>\n",
       "      <td>-1.642999</td>\n",
       "      <td>0.686196</td>\n",
       "      <td>-0.840565</td>\n",
       "      <td>1.943366</td>\n",
       "      <td>-1.035706</td>\n",
       "      <td>-1.099163</td>\n",
       "      <td>-0.754686</td>\n",
       "      <td>-1.125765</td>\n",
       "      <td>1.743481</td>\n",
       "      <td>-1.014739</td>\n",
       "      <td>-1.114636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.557978</td>\n",
       "      <td>-0.564393</td>\n",
       "      <td>-1.507937</td>\n",
       "      <td>1.487671</td>\n",
       "      <td>-1.114905</td>\n",
       "      <td>-1.059531</td>\n",
       "      <td>-1.111998</td>\n",
       "      <td>-0.918267</td>\n",
       "      <td>-0.739008</td>\n",
       "      <td>-1.036650</td>\n",
       "      <td>0.295515</td>\n",
       "      <td>-1.093342</td>\n",
       "      <td>-0.882296</td>\n",
       "      <td>1.777138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D       AxA       AxB       AxC  \\\n",
       "0  0.871354  1.539998  1.013701 -0.475045  0.780807  2.074419  1.571010   \n",
       "1  0.097133 -1.000501  0.144408 -0.361014 -0.184793 -0.625760  0.162509   \n",
       "2 -1.454749 -0.232121 -1.504488 -0.592531 -1.102080 -0.979806 -1.103892   \n",
       "3  0.805975 -1.433147  1.469045 -1.642999  0.686196 -0.840565  1.943366   \n",
       "4 -1.557978 -0.564393 -1.507937  1.487671 -1.114905 -1.059531 -1.111998   \n",
       "\n",
       "        AxD       BxB       BxC       BxD       CxC       CxD       DxD  \n",
       "0  0.096039  1.880247  2.246063  0.422893  0.984923  0.177586 -0.675447  \n",
       "1 -0.189062 -0.972482 -0.606603 -0.752361 -0.137652 -0.158191 -0.591777  \n",
       "2 -1.005014 -0.489840 -1.009996 -0.486138 -1.092955 -1.036416 -0.754062  \n",
       "3 -1.035706 -1.099163 -0.754686 -1.125765  1.743481 -1.014739 -1.114636  \n",
       "4 -0.918267 -0.739008 -1.036650  0.295515 -1.093342 -0.882296  1.777138  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=df3.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.39391332,  2.46557766, -1.62779726, ..., -0.22417927,\n",
       "         0.12985542,  0.07761826],\n",
       "       [-1.35265993, -0.18145862,  1.00877827, ..., -0.11967224,\n",
       "        -0.09125284, -0.15450927],\n",
       "       [-3.41052611, -0.11721703, -0.70427328, ...,  0.21465685,\n",
       "         0.41524234,  0.23797298],\n",
       "       ...,\n",
       "       [-0.67560659,  0.97584749, -2.22226443, ...,  0.08465935,\n",
       "        -0.19696135, -0.09884207],\n",
       "       [ 1.43610553, -1.15318529, -3.98359452, ..., -0.21929073,\n",
       "         0.03184544,  0.01273689],\n",
       "       [ 3.46392304,  2.2749638 ,  0.92806032, ...,  0.08216389,\n",
       "        -0.19495706,  0.26189016]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit_transform(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_var = pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_comp = (vec_var>1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca2 = PCA(n_components=pca_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat4 = pca2.fit_transform(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = df['A'] + df['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1543\n",
       "1    1066\n",
       "2     137\n",
       "3    1656\n",
       "4     106\n",
       "dtype: int32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['col'+str(i) for i in range(mat4.shape[1]+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame(index=df1.index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.loc[:,df5.columns[:-1]] = mat4\n",
    "df5.loc[:,df5.columns[-1]]  = Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col0</th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.39391</td>\n",
       "      <td>2.46558</td>\n",
       "      <td>-1.6278</td>\n",
       "      <td>-1.14291</td>\n",
       "      <td>1543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.35266</td>\n",
       "      <td>-0.181459</td>\n",
       "      <td>1.00878</td>\n",
       "      <td>-0.925217</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.41053</td>\n",
       "      <td>-0.117217</td>\n",
       "      <td>-0.704273</td>\n",
       "      <td>0.914964</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.999053</td>\n",
       "      <td>1.55006</td>\n",
       "      <td>2.02364</td>\n",
       "      <td>-3.35509</td>\n",
       "      <td>1656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.233</td>\n",
       "      <td>-1.93111</td>\n",
       "      <td>0.263968</td>\n",
       "      <td>2.67258</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       col0      col1      col2      col3  col4\n",
       "0   3.39391   2.46558   -1.6278  -1.14291  1543\n",
       "1  -1.35266 -0.181459   1.00878 -0.925217  1066\n",
       "2  -3.41053 -0.117217 -0.704273  0.914964   137\n",
       "3 -0.999053   1.55006   2.02364  -3.35509  1656\n",
       "4    -2.233  -1.93111  0.263968   2.67258   106"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN con dati originali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>755</td>\n",
       "      <td>948</td>\n",
       "      <td>788</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530</td>\n",
       "      <td>214</td>\n",
       "      <td>536</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>436</td>\n",
       "      <td>58</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>736</td>\n",
       "      <td>89</td>\n",
       "      <td>920</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>340</td>\n",
       "      <td>57</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C    D\n",
       "0  755  948  788  364\n",
       "1  530  214  536  397\n",
       "2   79  436   58  330\n",
       "3  736   89  920   26\n",
       "4   49  340   57  932"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Z'] = Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>755</td>\n",
       "      <td>948</td>\n",
       "      <td>788</td>\n",
       "      <td>364</td>\n",
       "      <td>1543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530</td>\n",
       "      <td>214</td>\n",
       "      <td>536</td>\n",
       "      <td>397</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>436</td>\n",
       "      <td>58</td>\n",
       "      <td>330</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>736</td>\n",
       "      <td>89</td>\n",
       "      <td>920</td>\n",
       "      <td>26</td>\n",
       "      <td>1656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>340</td>\n",
       "      <td>57</td>\n",
       "      <td>932</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C    D     Z\n",
       "0  755  948  788  364  1543\n",
       "1  530  214  536  397  1066\n",
       "2   79  436   58  330   137\n",
       "3  736   89  920   26  1656\n",
       "4   49  340   57  932   106"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data_tens = torch.from_numpy(in_data.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data_tens_train, in_data_tens_cv = train_test_split(in_data, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>755</td>\n",
       "      <td>948</td>\n",
       "      <td>788</td>\n",
       "      <td>364</td>\n",
       "      <td>1543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530</td>\n",
       "      <td>214</td>\n",
       "      <td>536</td>\n",
       "      <td>397</td>\n",
       "      <td>1066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>436</td>\n",
       "      <td>58</td>\n",
       "      <td>330</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>736</td>\n",
       "      <td>89</td>\n",
       "      <td>920</td>\n",
       "      <td>26</td>\n",
       "      <td>1656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>340</td>\n",
       "      <td>57</td>\n",
       "      <td>932</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>534</td>\n",
       "      <td>508</td>\n",
       "      <td>559</td>\n",
       "      <td>108</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>335</td>\n",
       "      <td>322</td>\n",
       "      <td>921</td>\n",
       "      <td>120</td>\n",
       "      <td>1256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>671</td>\n",
       "      <td>744</td>\n",
       "      <td>354</td>\n",
       "      <td>108</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>753</td>\n",
       "      <td>986</td>\n",
       "      <td>110</td>\n",
       "      <td>572</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>103</td>\n",
       "      <td>950</td>\n",
       "      <td>895</td>\n",
       "      <td>926</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A    B    C    D     Z\n",
       "0     755  948  788  364  1543\n",
       "1     530  214  536  397  1066\n",
       "2      79  436   58  330   137\n",
       "3     736   89  920   26  1656\n",
       "4      49  340   57  932   106\n",
       "...   ...  ...  ...  ...   ...\n",
       "9995  534  508  559  108  1093\n",
       "9996  335  322  921  120  1256\n",
       "9997  671  744  354  108  1025\n",
       "9998  753  986  110  572   863\n",
       "9999  103  950  895  926   998\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), slice(None, -1, None))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-07d6c43904b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_data_tens_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_data_tens_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_data_tens_cv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_data_tens_cv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\conda2020\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\conda2020\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2644\u001b[0m                 )\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2648\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), slice(None, -1, None))' is an invalid key"
     ]
    }
   ],
   "source": [
    "x_train = in_data_tens_train[:,:-1]\n",
    "y_train = in_data_tens_train[:,-1]\n",
    "x_cv = in_data_tens_cv[:,:-1]\n",
    "y_cv = in_data_tens_cv[:,-1]\n",
    "\n",
    "x_train.shape,y_train.shape,x_cv.shape,y_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = nn.Sequential(\n",
    "    nn.Linear(x_train.shape[1],250),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(250,250),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(250,250),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(250,250),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(250,1),\n",
    "    nn.ReLU(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11498.1699, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model(x_cv).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.SGD(nn_model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1144302.2500)\n",
      "tensor(nan)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-176-a4f898d5da04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#calcolo l'uscita\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#calcolo l'errore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m#calcolo del gradiente\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m#aggiornamento dei parametri\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#azzeramento del gradiente\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\conda2020\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\conda2020\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    y_pred = nn_model(x_train) #calcolo l'uscita\n",
    "    loss = error(y_pred, y_train.reshape(-1,1))  #calcolo l'errore\n",
    "    loss.backward()        #calcolo del gradiente\n",
    "    optimizer.step()       #aggiornamento dei parametri\n",
    "    optimizer.zero_grad()  #azzeramento del gradiente\n",
    "    if np.mod(i,100)==0:\n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape, y_train.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error(y_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in nn_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import math\n",
    "from sklearn import (\n",
    "    base, compose, decomposition, linear_model,\n",
    "    metrics, model_selection, multioutput,\n",
    "    neural_network, pipeline, preprocessing,\n",
    "    svm, utils\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchMLPClassifier(base.BaseEstimator, base.ClassifierMixin):\n",
    "\n",
    "    \"\"\"\n",
    "    Adapted from kaggle.com/graymant/pytorch-regression-with-sklearn-pipelines\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, output_dim=1, hidden_layer_dims=[100,],\n",
    "        num_epochs=1, learning_rate=0.01, batch_size=128, shuffle=False,\n",
    "        callbacks=[], use_gpu=False, verbose=1, use_bn=False, batches_per_epoch=None,\n",
    "    ):\n",
    "        self._history = None\n",
    "        self._model = None\n",
    "        if use_gpu and not torch.cuda.is_available():\n",
    "            raise RuntimeError('GPU was requested but is not available.')\n",
    "        \n",
    "        self._gpu = use_gpu\n",
    "\n",
    "        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n",
    "        values.pop(\"self\")\n",
    "\n",
    "        for arg, val in values.items():\n",
    "            setattr(self, arg, val)\n",
    "\n",
    "    def _build_model(self, input_dim):\n",
    "        self._layer_dims = [input_dim] + \\\n",
    "            self.hidden_layer_dims + [self.output_dim]\n",
    "\n",
    "        self._model = torch.nn.Sequential()\n",
    "        for idx, dim in enumerate(self._layer_dims):\n",
    "            if (idx < len(self._layer_dims) - 1):\n",
    "                module = torch.nn.Linear(dim, self._layer_dims[idx + 1])\n",
    "                torch.nn.init.xavier_uniform_(module.weight)\n",
    "                self._model.add_module(\"linear\" + str(idx), module)\n",
    "\n",
    "            if (idx < len(self._layer_dims) - 2):\n",
    "                if self.use_bn:\n",
    "                    self._model.add_module(\"bn\" + str(idx), torch.nn.BatchNorm1d(self._layer_dims[idx + 1]))\n",
    "                self._model.add_module(\"relu\" + str(idx), torch.nn.ReLU())\n",
    "\n",
    "        if self._gpu:\n",
    "            self._model = self._model.cuda()\n",
    "\n",
    "    def _train_model(self, X, y):\n",
    "        torch_x = torch.from_numpy(X).float()\n",
    "        torch_y = torch.from_numpy(y).float()\n",
    "        if self._gpu:\n",
    "            torch_x = torch_x.cuda()\n",
    "            torch_y = torch_y.cuda()\n",
    "\n",
    "        train = torch.utils.data.TensorDataset(torch_x, torch_y)\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train, batch_size=self.batch_size, shuffle=self.shuffle\n",
    "        )\n",
    "\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "#         loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self._model.parameters(), lr=self.learning_rate\n",
    "        )\n",
    "\n",
    "        self._history = {\"loss\": [], \"val_loss\": [], \"log_loss\": []}\n",
    "\n",
    "        def gen_():\n",
    "            if self.batches_per_epoch is None:\n",
    "                while True:\n",
    "                    yield from enumerate(train_loader)\n",
    "                    yield None\n",
    "            else:\n",
    "                iidx = 0\n",
    "                it = itertools.chain.from_iterable(iter(lambda:enumerate(train_loader), None))\n",
    "                while True:\n",
    "                    yield next(it)\n",
    "                    iidx += 1\n",
    "                    if not idx % self.batches_per_epoch:\n",
    "                        yield None\n",
    "                    \n",
    "        train_batches = gen_()\n",
    "        \n",
    "        finish = False\n",
    "        for epoch in range(self.num_epochs):\n",
    "            if finish:\n",
    "                break\n",
    "\n",
    "            loss = None\n",
    "            idx = 0\n",
    "            for batch in train_batches:\n",
    "                if batch is None:\n",
    "                    break\n",
    "\n",
    "                idx, (minibatch, target) = batch\n",
    "                y_pred = self._model(torch.autograd.Variable(minibatch))\n",
    "\n",
    "                loss = loss_fn(\n",
    "                    y_pred,\n",
    "                    torch.autograd.Variable(target.float())\n",
    "                )\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                print(loss)\n",
    "\n",
    "            y_labels = target.cpu().numpy() if self._gpu else target.numpy()\n",
    "            y_pred_results = y_pred.cpu().data.numpy() if self._gpu else y_pred.data.numpy()\n",
    "\n",
    "            loss_val = loss.data.cpu().numpy().item() if self._gpu else loss.data.numpy().item()\n",
    "            self._history[\"log_loss\"].append(loss_val)\n",
    "\n",
    "            if self.verbose > 0:\n",
    "                print(\n",
    "                    \"Results for epoch {}, log_loss {}\".format(\n",
    "                        epoch + 1, loss_val\n",
    "                    )\n",
    "                )\n",
    "            for callback in self.callbacks:\n",
    "                callback.call(self._model, self._history)\n",
    "                if callback.finish:\n",
    "                    finish = True\n",
    "                    break\n",
    "\n",
    "    def fit(self, X, y, reset = True):\n",
    "        assert (type(self.output_dim) == int), \"output_dim must be defined\"\n",
    "        \n",
    "        if reset:\n",
    "            self._build_model(*X.shape[1:])\n",
    "        self._train_model(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X, y=None):\n",
    "        return 1/(1 + np.exp(-self.predict_log_proba(X, y)))\n",
    "    \n",
    "    def predict_log_proba(self, X, y=None):\n",
    "        if self._history == None:\n",
    "            raise RuntimeError(\"Regressor has not been fit\")\n",
    "\n",
    "        results = []\n",
    "        split_size = math.ceil(len(X) / self.batch_size)\n",
    "\n",
    "        for batch in np.array_split(X, split_size):\n",
    "            x_pred = torch.autograd.Variable(torch.from_numpy(batch).float())\n",
    "            y_pred = self._model(x_pred.cuda() if self._gpu else x_pred)\n",
    "            y_pred_formatted = y_pred.cpu().data.numpy() if self._gpu else y_pred.data.numpy()\n",
    "            results.append(y_pred_formatted)\n",
    "\n",
    "        results = np.concatenate(results).astype(np.float)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = TorchMLPClassifier(hidden_layer_dims=[1024], use_bn=True, output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.loc[:,df.columns[:-1]].values\n",
    "y = df.loc[:,df.columns[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.batch_size = 128\n",
    "nn.num_epochs = 100\n",
    "nn.hidden_layer_dims = [2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-579.0176, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-11801.7246, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-22349.3848, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-34954.9258, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-45841.9453, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-58757.3438, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-65713.9453, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-79219.0156, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-95127.4062, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-107185.6406, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-126127.6719, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-139995.8594, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-158444.2031, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-180894.9219, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-194731.4844, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-214911.1406, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-234165.2812, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-258976.8125, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-275974.2500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-288467.2188, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-325242.5625, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-349879.3750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-372222.4375, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-378242.0312, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-442023.0312, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-454595.1562, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-484718.8750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-518279.6875, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-544299.3125, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-516911.1875, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-588178.1250, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-604949.7500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-701709.2500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-733076.8125, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-737745.9375, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-830560.5625, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-875278.6250, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-861263.9375, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-931113., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-968046.3750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-970578.0625, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1124595.5000, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1065466.3750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1194487.8750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1248741.3750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1316957.8750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1317692.1250, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1367336.3750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1372183.8750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1554319.6250, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1673610.7500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1587723.3750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1667169.8750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1744924., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1794243.8750, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1890560.7500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1959304., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-1961467.2500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-2065255.1250, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-2163285., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-2226725.7500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-2297149., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-2244824.5000, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-2525956., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-2530174.7500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-2801713., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-2645995.5000, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-2568433., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-2883068.7500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-2848678.7500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-3009317.5000, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-3040967.2500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-3109769., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-3335783.2500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-3365106.2500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-3560893.5000, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-3402675.7500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-3730560., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-3208174.2500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "Results for epoch 1, log_loss -3208174.25\n",
      "tensor(-3795456., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-3888861.7500, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-3893375., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-4203620., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-4296768.5000, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-4529299., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-4245414.5000, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-4406778., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(-4688808., grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-c6696f5b13e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-5a416160e8b8>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, reset)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-5a416160e8b8>\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\conda2020\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\conda2020\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nn.fit(x, y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [0.82693206],\n",
       "       [1.        ],\n",
       "       ...,\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.82693206]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn._model(torch.autograd.Variable(torch.from_numpy(x).type(torch.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.8170e+07],\n",
       "        [7.8927e+01],\n",
       "        [3.1063e+07],\n",
       "        ...,\n",
       "        [7.4568e+06],\n",
       "        [4.1472e+07],\n",
       "        [7.8927e+01]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-71f5ad408746>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\conda2020\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\conda2020\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    630\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m                                                   reduction=self.reduction)\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\conda2020\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   2577\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2579\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2580\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>561</td>\n",
       "      <td>474</td>\n",
       "      <td>580</td>\n",
       "      <td>970</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162</td>\n",
       "      <td>776</td>\n",
       "      <td>369</td>\n",
       "      <td>20</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>990</td>\n",
       "      <td>921</td>\n",
       "      <td>199</td>\n",
       "      <td>982</td>\n",
       "      <td>1189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>913</td>\n",
       "      <td>964</td>\n",
       "      <td>629</td>\n",
       "      <td>422</td>\n",
       "      <td>1542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>313</td>\n",
       "      <td>354</td>\n",
       "      <td>800</td>\n",
       "      <td>205</td>\n",
       "      <td>1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>118</td>\n",
       "      <td>143</td>\n",
       "      <td>527</td>\n",
       "      <td>884</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>115</td>\n",
       "      <td>206</td>\n",
       "      <td>354</td>\n",
       "      <td>877</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>669</td>\n",
       "      <td>816</td>\n",
       "      <td>63</td>\n",
       "      <td>41</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>863</td>\n",
       "      <td>319</td>\n",
       "      <td>538</td>\n",
       "      <td>156</td>\n",
       "      <td>1401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>261</td>\n",
       "      <td>25</td>\n",
       "      <td>144</td>\n",
       "      <td>738</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        A    B    C    D     Z\n",
       "0     561  474  580  970  1141\n",
       "1     162  776  369   20   531\n",
       "2     990  921  199  982  1189\n",
       "3     913  964  629  422  1542\n",
       "4     313  354  800  205  1113\n",
       "...   ...  ...  ...  ...   ...\n",
       "9995  118  143  527  884   645\n",
       "9996  115  206  354  877   469\n",
       "9997  669  816   63   41   732\n",
       "9998  863  319  538  156  1401\n",
       "9999  261   25  144  738   405\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
