{"paragraphs":[{"text":"%md\n\n- Ogni nodo del cluster di Spark contiene una o più partizioni.\n- Di default il numero di partizioni è settato pari al numero di cores disponibili nel cluster.\n- Ogni partizione è interamente contenuta in un unico worker.\n- Spark assegna un task per ogni partizione e ogni worker può processare un task per volta.\n\n","user":"admin","dateUpdated":"2019-12-11T12:02:35+0100","config":{"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"results":{},"enabled":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<ul>\n  <li>Ogni nodo del cluster di Spark contiene una o più partizioni.</li>\n  <li>Di default il numero di partizioni è settato pari al numero di cores disponibili nel cluster.</li>\n  <li>Ogni partizione è interamente contenuta in un unico worker.</li>\n  <li>Spark assegna un task per ogni partizione e ogni worker può processare un task per volta.</li>\n</ul>\n</div>"}]},"apps":[],"jobName":"paragraph_1576059074046_695604585","id":"20191211-111114_1565692295","dateCreated":"2019-12-11T11:11:14+0100","dateStarted":"2019-12-11T12:02:35+0100","dateFinished":"2019-12-11T12:02:35+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9777"},{"text":"%md\nPer vedere il numero di partizioni uso **getNumPartitions()**","user":"anonymous","dateUpdated":"2019-12-11T11:39:30+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Per vedere il numero di partizioni uso <strong>getNumPartitions()</strong></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1576059445016_-1452489620","id":"20191211-111725_28086690","dateCreated":"2019-12-11T11:17:25+0100","dateStarted":"2019-12-11T11:39:30+0100","dateFinished":"2019-12-11T11:39:30+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9778"},{"text":"val df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"globalpowerplantdatabasev120/*.csv\")\ndf.rdd.getNumPartitions","user":"admin","dateUpdated":"2019-12-11T12:41:36+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"df: org.apache.spark.sql.DataFrame = [country: string, country_long: string ... 22 more fields]\r\nres1: Int = 1\n"}]},"apps":[],"jobName":"paragraph_1576060770709_-2139155297","id":"20191211-113930_2105717002","dateCreated":"2019-12-11T11:39:30+0100","dateStarted":"2019-12-11T12:41:36+0100","dateFinished":"2019-12-11T12:41:53+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9779"},{"text":"%md\nQuesto setting definisce il numero minimo di partizioni quando un dataframe è creato per la prima volta:\n`sc.defaultMinPartitions`\nQuesto è definito internamente da Spark come il minimo tra defaultParallelism e 2, ciò significa che defaultMinPartitions non può essere più grande di 2. [RIF. 1]\n\n**defaultParallelism** è il numero di cores/Executors usato, che in Zeppelin di default è 1. Posso settare questo in una nuova **Sparkession** con il metodo **master(\"local[x]\")**.\n\nSi noti che anche allocando un numero alto di executor, il numero massimo di partizioni create è 2, questo significa che la creazione del rdd/dataframe al momento del caricamento dei dati può essere lenta. ","user":"admin","dateUpdated":"2019-12-11T13:30:25+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Questo setting definisce il numero minimo di partizioni quando un dataframe è creato per la prima volta:<br/><code>sc.defaultMinPartitions</code><br/>Questo è definito internamente da Spark come il minimo tra defaultParallelism e 2, ciò significa che defaultMinPartitions non può essere più grande di 2. [RIF. 1]</p>\n<p><strong>defaultParallelism</strong> è il numero di cores/Executors usato, che in Zeppelin di default è 1. Posso settare questo in una nuova <strong>Sparkession</strong> con il metodo <strong>master(&ldquo;local[x]&rdquo;)</strong>.</p>\n<p>Si noti che anche allocando un numero alto di executor, il numero massimo di partizioni create è 2, questo significa che la creazione del rdd/dataframe al momento del caricamento dei dati può essere lenta.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1576064215827_1297258228","id":"20191211-123655_801279717","dateCreated":"2019-12-11T12:36:55+0100","dateStarted":"2019-12-11T13:30:25+0100","dateFinished":"2019-12-11T13:30:25+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9780"},{"text":"import spark.implicits._\n\nprintln(f\"Numero di Executors: ${sc.defaultParallelism}\")\nprintln(f\"Numero minimo di partizioni: ${sc.defaultMinPartitions}\")","user":"admin","dateUpdated":"2019-12-11T14:50:33+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Numero di Executors: 2\r\nNumero minimo di partizioni: 2\r\nimport spark.implicits._\n"}]},"apps":[],"jobName":"paragraph_1576062601162_813364363","id":"20191211-121001_507255553","dateCreated":"2019-12-11T12:10:01+0100","dateStarted":"2019-12-11T14:50:33+0100","dateFinished":"2019-12-11T14:50:34+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9781"},{"text":"%md\nCi sono diversi modi di settare **sc.defaultParallelism**:\n- se uso **master(\"local[x]\")** per usare x cores, defaultParallelism viene settato a x\n- si può definire nello SparkSession, per es.:\n```val spark = SparkSession.builder().appName(\"TestPartitionNums\").master(\"local\").config(\"spark.default.parallelism\", 20).getOrCreate()```\n- si può settare nel file *spark-defaults.conf* con la linea: `spark.default.parallelism=20`\n- in Apache Zeppelin si può anche settare tra i parametri dell'interprete Spark, creando un nuovo parametro con `spark.default.parallelism=20`","user":"admin","dateUpdated":"2019-12-11T13:37:09+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Ci sono diversi modi di settare <strong>sc.defaultParallelism</strong>:<br/>- se uso <strong>master(&ldquo;local[x]&rdquo;)</strong> per usare x cores, defaultParallelism viene settato a x<br/>- si può definire nello SparkSession, per es.:<br/><code>val spark = SparkSession.builder().appName(&quot;TestPartitionNums&quot;).master(&quot;local&quot;).config(&quot;spark.default.parallelism&quot;, 20).getOrCreate()</code><br/>- si può settare nel file <em>spark-defaults.conf</em> con la linea: <code>spark.default.parallelism=20</code><br/>- in Apache Zeppelin si può anche settare tra i parametri dell&rsquo;interprete Spark, creando un nuovo parametro con <code>spark.default.parallelism=20</code></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1576064521977_2039630275","id":"20191211-124201_1141603656","dateCreated":"2019-12-11T12:42:01+0100","dateStarted":"2019-12-11T13:37:09+0100","dateFinished":"2019-12-11T13:37:09+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9782"},{"text":"spark.stop","user":"admin","dateUpdated":"2019-12-11T12:42:16+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1576062018717_-1405023364","id":"20191211-120018_821827504","dateCreated":"2019-12-11T12:00:18+0100","dateStarted":"2019-12-11T12:42:16+0100","dateFinished":"2019-12-11T12:42:16+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9783"},{"text":"import org.apache.spark.sql.SparkSession\nval spark = SparkSession.builder.master(\"local[16]\").getOrCreate()\nval sc = spark.sparkContext\n\nval df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"globalpowerplantdatabasev120/*.csv\")\ndf.rdd.getNumPartitions","user":"admin","dateUpdated":"2019-12-11T12:42:19+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.SparkSession\r\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@78b6cc3c\r\nsc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@544cbb2\r\ndf: org.apache.spark.sql.DataFrame = [country: string, country_long: string ... 22 more fields]\r\nres4: Int = 2\n"}]},"apps":[],"jobName":"paragraph_1576061215031_1329482832","id":"20191211-114655_2070483524","dateCreated":"2019-12-11T11:46:55+0100","dateStarted":"2019-12-11T12:42:19+0100","dateFinished":"2019-12-11T12:42:19+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9784"},{"text":"println(f\"Numero di Executors: ${sc.defaultParallelism}\")\nprintln(f\"Numero minimo di partizioni: ${sc.defaultMinPartitions}\")","user":"admin","dateUpdated":"2019-12-11T14:50:58+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Numero di Executors: 2\r\nNumero minimo di partizioni: 2\r\n"}]},"apps":[],"jobName":"paragraph_1576062033906_-1424557200","id":"20191211-120033_1744201914","dateCreated":"2019-12-11T12:00:33+0100","dateStarted":"2019-12-11T14:50:58+0100","dateFinished":"2019-12-11T14:50:58+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9785"},{"text":"%md\nUn altro parametro utile per definire il numero di partizioni è\n`spark.sql.files.maxPartitionBytes`\nCome si evince dal nome questo parametro definisce lo spazio su disco per ogni partizione.\nSetto questo parametro a 1M (il default è 128MB), con un file dati da 7.55MB, implica che vengono create **floor(7.55M/1M) = 8** partizioni.\nSi noti che in questo modo viene anche rispettato il parametro **defaultMinPartitions**.","user":"admin","dateUpdated":"2019-12-11T15:42:35+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Un altro parametro utile per definire il numero di partizioni è<br/><code>spark.sql.files.maxPartitionBytes</code><br/>Come si evince dal nome questo parametro definisce lo spazio su disco per ogni partizione.<br/>Setto questo parametro a 1M (il default è 128MB), con un file dati da 7.55MB, implica che vengono create <strong>floor(7.55M/1M) = 8</strong> partizioni.<br/>Si noti che in questo modo viene anche rispettato il parametro <strong>defaultMinPartitions</strong>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1576062387516_-2001321506","id":"20191211-120627_1269901082","dateCreated":"2019-12-11T12:06:27+0100","dateStarted":"2019-12-11T15:42:35+0100","dateFinished":"2019-12-11T15:42:35+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9786"},{"text":"spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"1000000\")\nval df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"globalpowerplantdatabasev120/*.csv\")\n\nprintln(f\"Numero di Executors: ${sc.defaultParallelism}\")\nprintln(f\"Numero minimo di partizioni: ${sc.defaultMinPartitions}\")\nprintln(f\"Numero di partizioni: ${df.rdd.getNumPartitions}\")","user":"admin","dateUpdated":"2019-12-11T14:51:27+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Numero di Executors: 2\r\nNumero minimo di partizioni: 2\r\nNumero di partizioni: 8\r\ndf: org.apache.spark.sql.DataFrame = [country: string, country_long: string ... 22 more fields]\n"}]},"apps":[],"jobName":"paragraph_1576062683922_-1150818995","id":"20191211-121123_739577557","dateCreated":"2019-12-11T12:11:23+0100","dateStarted":"2019-12-11T14:51:27+0100","dateFinished":"2019-12-11T14:51:28+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9787"},{"text":"spark.stop\nsc.stop","user":"admin","dateUpdated":"2019-12-11T14:55:24+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1576064055707_-769807528","id":"20191211-123415_1070340983","dateCreated":"2019-12-11T12:34:15+0100","dateStarted":"2019-12-11T14:55:24+0100","dateFinished":"2019-12-11T14:55:24+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9788"},{"text":"import org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.SparkSession\n\nval conf = new SparkConf().setMaster(\"local[16]\").setAppName(\"NewApp\")\nval sc = new SparkContext(conf)\nval spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n\nval df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"globalpowerplantdatabasev120/*.csv\")\n\nprintln(f\"Numero di Executors: ${sc.defaultParallelism}\")\nprintln(f\"Numero minimo di partizioni: ${sc.defaultMinPartitions}\")\nprintln(f\"Numero di partizioni: ${df.rdd.getNumPartitions}\")","user":"admin","dateUpdated":"2019-12-11T14:55:26+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Numero di Executors: 16\r\nNumero minimo di partizioni: 2\r\nNumero di partizioni: 2\r\nimport org.apache.spark.SparkConf\r\nimport org.apache.spark.SparkContext\r\nimport org.apache.spark.sql.SparkSession\r\nconf: org.apache.spark.SparkConf = org.apache.spark.SparkConf@7ea61de8\r\nsc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@4d4345e9\r\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@40feb6ff\r\ndf: org.apache.spark.sql.DataFrame = [country: string, country_long: string ... 22 more fields]\n"}]},"apps":[],"jobName":"paragraph_1576063273899_972506315","id":"20191211-122113_379911460","dateCreated":"2019-12-11T12:21:13+0100","dateStarted":"2019-12-11T14:55:26+0100","dateFinished":"2019-12-11T14:55:27+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9789"},{"text":"val newdf = df.groupBy(\"country\").max(\"estimated_generation_gwh\")\nnewdf.rdd.getNumPartitions","user":"admin","dateUpdated":"2019-12-11T16:02:29+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"newdf: org.apache.spark.sql.DataFrame = [country: string, max(estimated_generation_gwh): double]\r\nres31: Int = 200\n"}]},"apps":[],"jobName":"paragraph_1576072394324_-937478376","id":"20191211-145314_1450041834","dateCreated":"2019-12-11T14:53:14+0100","dateStarted":"2019-12-11T16:02:18+0100","dateFinished":"2019-12-11T16:02:18+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9790"},{"text":"%md\nCome si vede sopra dopo le operazioni **groupBy()** e **aggregate** ho 200 partizioni, questo perchè il parametro spark.sql.shuffle.partitions è settato a 200. Ricordiamo che quest'ultimo fissa il numero di partizioni create da un'operazione con implica uno shuffle, come ad esempio **groupBy**.\n\nNella UI di Spark si può vedere come è cambiato il numero di task e conseguentemente di partizioni, da 1 a 200.\n![spark ui stages](https://www.1week4.com/wp-content/uploads/2019/12/spark-ui-stages1.jpg)","user":"admin","dateUpdated":"2019-12-11T16:06:16+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Come si vede sopra dopo le operazioni <strong>groupBy()</strong> e <strong>aggregate</strong> ho 200 partizioni, questo perchè il parametro spark.sql.shuffle.partitions è settato a 200. Ricordiamo che quest&rsquo;ultimo fissa il numero di partizioni create da un&rsquo;operazione con implica uno shuffle, come ad esempio <strong>groupBy</strong>.</p>\n<p>Nella UI di Spark si può vedere come è cambiato il numero di task e conseguentemente di partizioni, da 1 a 200.<br/><img src=\"https://www.1week4.com/wp-content/uploads/2019/12/spark-ui-stages1.jpg\" alt=\"spark ui stages\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1576075992677_-1462959047","id":"20191211-155312_1902930156","dateCreated":"2019-12-11T15:53:12+0100","dateStarted":"2019-12-11T16:06:16+0100","dateFinished":"2019-12-11T16:06:16+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9791"},{"text":"//   Default min number of partitions for Hadoop RDDs when not given by user\r\n//   Notice that we use math.min so the \"defaultMinPartitions\" cannot be higher than 2.\r\n//   The reasons for this are discussed in https://github.com/mesos/spark/pull/718\r\n//   \r\n//  def defaultMinPartitions: Int = math.min(defaultParallelism, 2)","user":"admin","dateUpdated":"2019-12-11T12:57:56+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576065277360_137080930","id":"20191211-125437_1840307153","dateCreated":"2019-12-11T12:54:37+0100","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:9792"},{"text":"%md\nRiferimenti\n1. [Spark Github](https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SparkContext.scala#L799)","user":"admin","dateUpdated":"2019-12-11T13:01:12+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Riferimenti<br/>1. <a href=\"https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SparkContext.scala#L799\">Spark Github</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1576065643809_1978105441","id":"20191211-130043_314232691","dateCreated":"2019-12-11T13:00:43+0100","dateStarted":"2019-12-11T13:01:12+0100","dateFinished":"2019-12-11T13:01:12+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9793"},{"text":"%md\n","user":"admin","dateUpdated":"2019-12-11T13:01:03+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576065663003_957701437","id":"20191211-130103_1686291439","dateCreated":"2019-12-11T13:01:03+0100","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:9794"}],"name":"Partitions","id":"2EVHDG6AD","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"personalizedMode":"false","isZeppelinNotebookCronEnable":false,"looknfeel":"default"},"info":{}}