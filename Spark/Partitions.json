{"paragraphs":[{"text":"%md\n## Cosa sono le partizioni di Apache Spark?\n\n## È utile sapere che\nNel memorizzare i dati in partizioni vengono seguite queste regole:\n- Il numero di partizioni che vengono generate dipende dal numero di cores \n- Ogni nodo (executor) del cluster di Spark contiene una o più partizioni\n- Di default il numero di partizioni dovrebbe essere settato pari al numero di cores disponibili nel cluster, purtroppo non si può fissare direttamente il numero di partizioni. **NO NO NO non si può settare direttamente il numero delle partizioni** \n- Ogni partizione è interamente contenuta in un unico worker (o executor???)\n- Spark assegna un task per ogni partizione e di default ogni core può processare un task per volta\n\n\n","user":"admin","dateUpdated":"2020-01-05T15:51:43+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Cosa sono le partizioni di Apache Spark?</h2>\n<h2>È utile sapere che</h2>\n<p>Nel memorizzare i dati in partizioni vengono seguite queste regole:<br/>- Il numero di partizioni che vengono generate dipende dal numero di cores<br/>- Ogni nodo (executor) del cluster di Spark contiene una o più partizioni<br/>- Di default il numero di partizioni dovrebbe essere settato pari al numero di cores disponibili nel cluster, purtroppo non si può fissare direttamente il numero di partizioni. <strong>NO NO NO non si può settare direttamente il numero delle partizioni</strong><br/>- Ogni partizione è interamente contenuta in un unico worker (o executor???)<br/>- Spark assegna un task per ogni partizione e di default ogni core può processare un task per volta</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578075426250_154308660","id":"20191211-111114_1565692295","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-05T15:51:43+0100","dateFinished":"2020-01-05T15:51:43+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15817"},{"text":"%md\n### Esempio di partitioning\nUn esempio per capire l'importanza del numero di partizioni.\n\nSupponiamo di avere un cluster con 4 core, e che i dati vengono suddivisi in 5 partizioni....\n\nUn numero di partizioni suggerito è pari al numero di cores del cluster. In questo modo ogni nodo (supponendo 1 nodo = 1 core) riceve una partizione, e ho un numero di task pari al numero delle partizioni (core). L'utilizzo del cluster è al 100%, ovvero o tutti i nodi sono impegnati. \n\n#FIGURA SOTTO\n\n\n\n","user":"admin","dateUpdated":"2020-01-05T03:22:53+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Esempio di partitioning</h3>\n<p>Un esempio per capire l&rsquo;importanza del numero di partizioni.</p>\n<p>Supponiamo di avere un cluster con 4 core, e che i dati vengono suddivisi in 5 partizioni&hellip;.</p>\n<p>Un numero di partizioni suggerito è pari al numero di cores del cluster. In questo modo ogni nodo (supponendo 1 nodo = 1 core) riceve una partizione, e ho un numero di task pari al numero delle partizioni (core). L&rsquo;utilizzo del cluster è al 100%, ovvero o tutti i nodi sono impegnati. </p>\n<p>#FIGURA SOTTO</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578092639454_2089203066","id":"20200104-000359_1766048439","dateCreated":"2020-01-04T00:03:59+0100","dateStarted":"2020-01-05T03:22:53+0100","dateFinished":"2020-01-05T03:22:53+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15818"},{"text":"%md\nPer vedere il numero di partizioni uso **getNumPartitions()** o **df.rdd.pastions.size()**.\nCarico un dataset di 7.55MB in un dataframe e controllo subito in quante partizioni è suddiviso il dataframe.\n","user":"admin","dateUpdated":"2020-01-05T16:27:55+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Per vedere il numero di partizioni uso <strong>getNumPartitions()</strong> o <strong>df.rdd.pastions.size()</strong>.<br/>Carico un dataset di 7.55MB in un dataframe e controllo subito in quante partizioni è suddiviso il dataframe.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578075426287_966789376","id":"20191211-111725_28086690","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-05T16:27:55+0100","dateFinished":"2020-01-05T16:27:55+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15819"},{"text":"val df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"globalpowerplantdatabasev120/*.csv\")\nprintln(f\"Numero di partizioni del dataframe: ${df.rdd.partitions.size}\")","user":"admin","dateUpdated":"2020-01-05T18:40:17+0100","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Numero di partizioni del dataframe: 2\r\ndf: org.apache.spark.sql.DataFrame = [country: string, country_long: string ... 22 more fields]\n"}]},"apps":[],"jobName":"paragraph_1578075426290_1259073957","id":"20191211-113930_2105717002","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-05T18:40:17+0100","dateFinished":"2020-01-05T18:40:21+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15820"},{"text":"%md\nPerché 2 partizioni soltanto?\nPerché Spark parte di default con due **executors** e un core per ogni executor. Per settare un numero di executors (cores) più alto si può usare **--num-executors** (e **--executor-cores**) al momento di lanciare il cluster.\n\nInvece di --num-executors si può settare la proprietà **spark.executor.instances**.\n\n","user":"admin","dateUpdated":"2020-01-05T17:58:57+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Perché 2 partizioni soltanto?<br/>Perché Spark parte di default con due <strong>executors</strong> e un core per ogni executor. Per settare un numero di executors (cores) più alto si può usare <strong>&ndash;num-executors</strong> (e <strong>&ndash;executor-cores</strong>) al momento di lanciare il cluster.</p>\n<p>Invece di &ndash;num-executors si può settare la proprietà <strong>spark.executor.instances</strong>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578238082308_-1436122792","id":"20200105-162802_1539673061","dateCreated":"2020-01-05T16:28:02+0100","dateStarted":"2020-01-05T17:58:57+0100","dateFinished":"2020-01-05T17:59:05+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15821"},{"text":"spark.stop","user":"admin","dateUpdated":"2020-01-05T18:09:12+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1578243794050_-1934909703","id":"20200105-180314_546314396","dateCreated":"2020-01-05T18:03:14+0100","dateStarted":"2020-01-05T18:09:12+0100","dateFinished":"2020-01-05T18:09:13+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15822"},{"text":"import org.apache.spark.sql.SparkSession\n\nval spark = SparkSession.builder.master(\"local[4]\").config(\"spark.executor.instances\", 4)\n                                                   .config(\"spark.default.parallelism\", 4).getOrCreate()\n\n\nval numExecs = spark.conf.get(\"spark.executor.instances\")\nprintln(f\"Numero di executors ${numExecs}\" )","user":"admin","dateUpdated":"2020-01-05T18:40:09+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Numero di executors 4\r\nimport org.apache.spark.sql.SparkSession\r\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@1093c6f8\r\nnumExecs: String = 4\n"}]},"apps":[],"jobName":"paragraph_1578241541535_-370809236","id":"20200105-172541_599899694","dateCreated":"2020-01-05T17:25:41+0100","dateStarted":"2020-01-05T18:40:09+0100","dateFinished":"2020-01-05T18:40:11+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15823"},{"text":"%md\n\nIl setting `sc.defaultMinPartitions` definisce il numero minimo di partizioni quando il dataframe è creato:\n\nQuesto parametro è definito internamente da Spark come il minimo tra defaultParallelism e 2, ciò significa che defaultMinPartitions non può essere più piccolo di 2. [vedi riferimento 1]\n\n**defaultParallelism** viene settato di default pari al numero di cores usato, **NO** che in Zeppelin di default è 1 **NO**. Posso settare questo in una nuova **Sparkession** con il metodo **master(\"local[x]\")**.\n\nSi noti che anche allocando un numero alto di executor, il numero minimo di partizioni create è 2.\n\n\n","user":"admin","dateUpdated":"2020-01-05T03:59:08+0100","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Il setting <code>sc.defaultMinPartitions</code> definisce il numero minimo di partizioni quando il dataframe è creato:</p>\n<p>Questo parametro è definito internamente da Spark come il minimo tra defaultParallelism e 2, ciò significa che defaultMinPartitions non può essere più piccolo di 2. [vedi riferimento 1]</p>\n<p><strong>defaultParallelism</strong> viene settato di default pari al numero di cores usato, <strong>NO</strong> che in Zeppelin di default è 1 <strong>NO</strong>. Posso settare questo in una nuova <strong>Sparkession</strong> con il metodo <strong>master(&ldquo;local[x]&rdquo;)</strong>.</p>\n<p>Si noti che anche allocando un numero alto di executor, il numero minimo di partizioni create è 2.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578075426298_-2004423481","id":"20191211-123655_801279717","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-05T03:33:46+0100","dateFinished":"2020-01-05T03:33:46+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15824"},{"text":"println(f\"sc.defaultParallelism: ${sc.defaultParallelism}\")\nprintln(f\"Numero minimo di partizioni: ${sc.defaultMinPartitions}\")","user":"admin","dateUpdated":"2020-01-05T03:34:07+0100","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sc.defaultParallelism: 4\r\nNumero minimo di partizioni: 2\r\n"}]},"apps":[],"jobName":"paragraph_1578075426301_85215137","id":"20191211-121001_507255553","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-05T03:34:07+0100","dateFinished":"2020-01-05T03:34:09+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15825"},{"text":"%md\nDiversi settaggi influiscono sul valore di **sc.defaultParallelism**:\n- se uso **master(\"local[x]\")** per usare x cores, defaultParallelism viene settato a x\n- si può definire nello SparkSession, per es.:\n```val spark = SparkSession.builder().appName(\"TestPartitionNums\").master(\"local\").config(\"spark.default.parallelism\", 20).getOrCreate()```\n- si può settare nel file *spark-defaults.conf* con il settaggio: `spark.default.parallelism=20`\n- in Apache Zeppelin si può anche settare nella GUI tra i parametri dell'interprete Spark, creando un nuovo parametro con `spark.default.parallelism=20`\n\n\n","user":"admin","dateUpdated":"2020-01-05T03:35:44+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Diversi settaggi influiscono sul valore di <strong>sc.defaultParallelism</strong>:<br/>- se uso <strong>master(&ldquo;local[x]&rdquo;)</strong> per usare x cores, defaultParallelism viene settato a x<br/>- si può definire nello SparkSession, per es.:<br/><code>val spark = SparkSession.builder().appName(&quot;TestPartitionNums&quot;).master(&quot;local&quot;).config(&quot;spark.default.parallelism&quot;, 20).getOrCreate()</code><br/>- si può settare nel file <em>spark-defaults.conf</em> con il settaggio: <code>spark.default.parallelism=20</code><br/>- in Apache Zeppelin si può anche settare nella GUI tra i parametri dell&rsquo;interprete Spark, creando un nuovo parametro con <code>spark.default.parallelism=20</code></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578075426305_-904639089","id":"20191211-124201_1141603656","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-05T03:35:44+0100","dateFinished":"2020-01-05T03:35:44+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15826"},{"text":"spark.stop","user":"admin","dateUpdated":"2020-01-03T19:17:06+0100","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1578075426309_586607093","id":"20191211-120018_821827504","dateCreated":"2020-01-03T19:17:06+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15827"},{"text":"import org.apache.spark.sql.SparkSession\nval spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\nval sc = spark.sparkContext\n\nval df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"globalpowerplantdatabasev120/*.csv\")\ndf.rdd.getNumPartitions","user":"admin","dateUpdated":"2020-01-05T03:22:39+0100","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.sql.SparkSession\r\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@78b6cc3c\r\nsc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@544cbb2\r\ndf: org.apache.spark.sql.DataFrame = [country: string, country_long: string ... 22 more fields]\r\nres4: Int = 2\n"}]},"apps":[],"jobName":"paragraph_1578075426313_181063797","id":"20191211-114655_2070483524","dateCreated":"2020-01-03T19:17:06+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15828"},{"text":"println(f\"sc.defaultParallelism: ${sc.defaultParallelism}\")\nprintln(f\"Numero minimo di partizioni: ${sc.defaultMinPartitions}\")","user":"admin","dateUpdated":"2020-01-05T03:36:26+0100","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sc.defaultParallelism: 4\r\nNumero minimo di partizioni: 2\r\n"}]},"apps":[],"jobName":"paragraph_1578075426315_-2061022124","id":"20191211-120033_1744201914","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-05T03:36:26+0100","dateFinished":"2020-01-05T03:36:29+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15829"},{"text":"%md\nIl parametro fondamentale per capire quante partizioni vengono generate è\n`spark.sql.files.maxPartitionBytes`\nCome si evince dal nome, questo parametro definisce il massimo spazio su disco per ogni partizione.\nSetto questo parametro a 1M (il default è 128MB), con un file dati da 7.55MB, implica che vengono create **ceil(7.55M/1M) = 8** partizioni.\nSi noti che viene anche rispettato il parametro **defaultMinPartitions** (= 2).\n\n\n","user":"admin","dateUpdated":"2020-01-05T03:37:09+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Il parametro fondamentale per capire quante partizioni vengono generate è<br/><code>spark.sql.files.maxPartitionBytes</code><br/>Come si evince dal nome, questo parametro definisce il massimo spazio su disco per ogni partizione.<br/>Setto questo parametro a 1M (il default è 128MB), con un file dati da 7.55MB, implica che vengono create <strong>ceil(7.55M/1M) = 8</strong> partizioni.<br/>Si noti che viene anche rispettato il parametro <strong>defaultMinPartitions</strong> (= 2).</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578075426317_-883455244","id":"20191211-120627_1269901082","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-05T03:37:09+0100","dateFinished":"2020-01-05T03:37:09+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15830"},{"text":"spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"1000000\")\nval df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"globalpowerplantdatabasev120/*.csv\")\n\nprintln(f\"sc.defaultParallelism: ${sc.defaultParallelism}\")\nprintln(f\"Numero minimo di partizioni: ${sc.defaultMinPartitions}\")\nprintln(f\"Numero effettivo di partizioni: ${df.rdd.getNumPartitions}\")","user":"admin","dateUpdated":"2020-01-05T03:38:21+0100","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"sc.defaultParallelism: 4\r\nNumero minimo di partizioni: 2\r\nNumero di partizioni: 8\r\ndf: org.apache.spark.sql.DataFrame = [country: string, country_long: string ... 22 more fields]\n"}]},"apps":[],"jobName":"paragraph_1578075426319_125766074","id":"20191211-121123_739577557","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-05T03:37:45+0100","dateFinished":"2020-01-05T03:37:50+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15831"},{"user":"admin","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1578191901819_1706451812","id":"20200105-033821_837933988","dateCreated":"2020-01-05T03:38:21+0100","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:15832"},{"text":"spark.stop\nsc.stop","user":"admin","dateUpdated":"2020-01-05T03:38:25+0100","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1578075426321_1702799828","id":"20191211-123415_1070340983","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-05T03:38:25+0100","dateFinished":"2020-01-05T03:38:26+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15833"},{"text":"%md \nSi noti che con le impostazioni di default usate sotto ho 4 cores e 2 partizioni. Nel momento in cui verranno fatti i primi calcoli sui dati, verrà assegnato un task per ogni partizione, ogni task girerà su un core. Avremo pertanto che solo 2 cores saranno utilizzati, con grosso spreco di risorse (2 cores inutilizzati) e un maggior tempo di elaborazione.\n\nRicordiamo: **N partizioni => N task => N cores utilizzati** \n\n\n\n","user":"admin","dateUpdated":"2020-01-05T03:46:37+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Si noti che con le impostazioni di default usate sotto ho 4 cores e 2 partizioni. Nel momento in cui verranno fatti i primi calcoli sui dati, verrà assegnato un task per ogni partizione, ogni task girerà su un core. Avremo pertanto che solo 2 cores saranno utilizzati, con grosso spreco di risorse (2 cores inutilizzati) e un maggior tempo di elaborazione.</p>\n<p>Ricordiamo: <strong>N partizioni =&gt; N task =&gt; N cores utilizzati</strong></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578192000918_1484438083","id":"20200105-034000_1029880386","dateCreated":"2020-01-05T03:40:00+0100","dateStarted":"2020-01-05T03:46:37+0100","dateFinished":"2020-01-05T03:46:37+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15834"},{"text":"import org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.SparkSession\n\nval conf = new SparkConf().setMaster(\"local[*]\").setAppName(\"NewApp\")\nval sc = new SparkContext(conf)\nval spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n\nval df = spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"globalpowerplantdatabasev120/*.csv\")\n\nprintln(f\"Numero di Executors: ${sc.defaultParallelism}\")\nprintln(f\"Numero minimo di partizioni: ${sc.defaultMinPartitions}\")\nprintln(f\"Numero di partizioni: ${df.rdd.getNumPartitions}\")","user":"admin","dateUpdated":"2020-01-05T03:38:27+0100","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Numero di Executors: 4\r\nNumero minimo di partizioni: 2\r\nNumero di partizioni: 2\r\nimport org.apache.spark.SparkConf\r\nimport org.apache.spark.SparkContext\r\nimport org.apache.spark.sql.SparkSession\r\nconf: org.apache.spark.SparkConf = org.apache.spark.SparkConf@2a68dd0b\r\nsc: org.apache.spark.SparkContext = org.apache.spark.SparkContext@6fc8f8ab\r\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@3e7cb231\r\ndf: org.apache.spark.sql.DataFrame = [country: string, country_long: string ... 22 more fields]\n"}]},"apps":[],"jobName":"paragraph_1578075426323_-741954781","id":"20191211-122113_379911460","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-05T03:38:27+0100","dateFinished":"2020-01-05T03:38:37+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15835"},{"text":"%md\nPer uno sfruttamento ottimale del cluster dovremmo settare **spark.sql.files.maxPartitionBytes** in modo tale da avere un numero di partizioni pari a 4: se il file è di 7.55MB questo significa spark.sql.files.maxPartitionBytes = 2M","user":"admin","dateUpdated":"2020-01-05T03:57:29+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Per uno sfruttamento ottimale del cluster dovremmo settare <strong>spark.sql.files.maxPartitionBytes</strong> in modo tale da avere un numero di partizioni pari a 4: se il file è di 7.55MB questo significa spark.sql.files.maxPartitionBytes = 2M</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578192465967_-1952142475","id":"20200105-034745_1183650256","dateCreated":"2020-01-05T03:47:45+0100","dateStarted":"2020-01-05T03:57:29+0100","dateFinished":"2020-01-05T03:57:29+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15836"},{"text":"%md\nAbbiamo visto come cambia il numero delle partizioni quando una struttura di **dati in ingresso viene generata**.\n\nMa il numero delle partizioni non è fisso dall'inizio alla fine della applicazione, infatti esso cambia se triggeriamo uno shuffle dei dati, ovvero se utilizziamo una trasformazione che implica uno shuffle (**wide transformation**). Per esempio ...\n\nCome si può vedere sotto il numero delle partizioni dopo le operazioni **groupBy()** e **max()** è diventato 200. Perchè?\n\n","user":"admin","dateUpdated":"2020-01-05T03:57:48+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Abbiamo visto come cambia il numero delle partizioni quando una struttura di <strong>dati in ingresso viene generata</strong>.</p>\n<p>Ma il numero delle partizioni non è fisso dall&rsquo;inizio alla fine della applicazione, infatti esso cambia se triggeriamo uno shuffle dei dati, ovvero se utilizziamo una trasformazione che implica uno shuffle (**wide transformation**). Per esempio &hellip;</p>\n<p>Come si può vedere sotto il numero delle partizioni dopo le operazioni <strong>groupBy()</strong> e <strong>max()</strong> è diventato 200. Perchè?</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578190803819_-567381686","id":"20200105-032003_1472496855","dateCreated":"2020-01-05T03:20:03+0100","dateStarted":"2020-01-05T03:57:48+0100","dateFinished":"2020-01-05T03:57:48+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15837"},{"text":"val newdf = df.groupBy(\"country\").max(\"estimated_generation_gwh\")\nnewdf.rdd.getNumPartitions","user":"admin","dateUpdated":"2020-01-03T19:17:06+0100","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"newdf: org.apache.spark.sql.DataFrame = [country: string, max(estimated_generation_gwh): double]\r\nres31: Int = 200\n"}]},"apps":[],"jobName":"paragraph_1578075426325_-182387447","id":"20191211-145314_1450041834","dateCreated":"2020-01-03T19:17:06+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15838"},{"user":"admin","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1578133553113_-1453135732","id":"20200104-112553_25467890","dateCreated":"2020-01-04T11:25:53+0100","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:15839"},{"text":"%md\nCome si vede sopra dopo le operazioni **groupBy()** e **aggregate** ho 200 partizioni, questo perchè il parametro spark.sql.shuffle.partitions è settato a 200. Ricordiamo che quest'ultimo fissa il numero di partizioni create da un'operazione che1 implica uno shuffle, come ad esempio **groupBy**.\n\nNella UI di Spark si può vedere come è cambiato il numero di task e conseguentemente di partizioni, da 1 a 200.\n![spark ui stages](https://www.1week4.com/wp-content/uploads/2019/12/spark-ui-stages1.jpg)","user":"admin","dateUpdated":"2020-01-04T00:29:15+0100","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Come si vede sopra dopo le operazioni <strong>groupBy()</strong> e <strong>aggregate</strong> ho 200 partizioni, questo perchè il parametro spark.sql.shuffle.partitions è settato a 200. Ricordiamo che quest&rsquo;ultimo fissa il numero di partizioni create da un&rsquo;operazione che1 implica uno shuffle, come ad esempio <strong>groupBy</strong>.</p>\n<p>Nella UI di Spark si può vedere come è cambiato il numero di task e conseguentemente di partizioni, da 1 a 200.<br/><img src=\"https://www.1week4.com/wp-content/uploads/2019/12/spark-ui-stages1.jpg\" alt=\"spark ui stages\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578075426328_923539663","id":"20191211-155312_1902930156","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-03T19:30:48+0100","dateFinished":"2020-01-03T19:30:48+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15840"},{"text":"%md\n## spark.executor.cores\n## spark.task.cpus","user":"admin","dateUpdated":"2020-01-04T01:31:17+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1578097842659_898627454","id":"20200104-013042_456316799","dateCreated":"2020-01-04T01:30:42+0100","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:15841"},{"text":"//   Default min number of partitions for Hadoop RDDs when not given by user\r\n//   Notice that we use math.min so the \"defaultMinPartitions\" cannot be higher than 2.\r\n//   The reasons for this are discussed in https://github.com/mesos/spark/pull/718\r\n//   \r\n//  def defaultMinPartitions: Int = math.min(defaultParallelism, 2)","user":"admin","dateUpdated":"2020-01-03T19:17:06+0100","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1578075426330_-1257231340","id":"20191211-125437_1840307153","dateCreated":"2020-01-03T19:17:06+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15842"},{"text":"%md\n| settaggio | default | spiegazione |\n|---------|---------|-------------|\n|spark.driver.cores|1|setta il numero di cores usati dal driver|\n|spark.executor.cores|1 in modo YARN. Tutti i cores disponibili in modo Spark standalone e con Mesos | il numero di cores per ogni executor in fase di lancio del nodo|\n|spark.task.cpu | 1 | numero di task da allocare per ciascun core|\n|spark.cores.max| non settato | il massimo numero di cores del cluster (totale, non per ogni executor) da assegnare **all'applicazione**. Solo per Spark standalone e Mesos \"coarse-grained\" |\n|spark.deploy.defaultCores| illimitato | numero default di cores del cluster da assegnare in Spark standalone se non è assegnato spark.cores.max. Si può usare per limitare il numero di cores da assegnare a diversi user di un cluster condiviso|\n|spark.default.parallelism <br>sc.defaultParallelism| numero di cores??? | numero di default delle partizioni generate da operazioni quali *join* e *reduceByKey* e *parallelize*|\n\n\n#### Esempio\nSupponendo di essere in **cluster mode**, settando: \n- spark.cores.max = 5\n- spark.driver.cores = 1\n- spark.executor.cores = 2\n\navrò un numero di executors pari a\n\n#executors = (spark.cores.max - spark.driver.cores)/spark.executor.cores = 2\n\n\n","user":"admin","dateUpdated":"2020-01-05T18:28:06+0100","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<table>\n  <thead>\n    <tr>\n      <th>settaggio </th>\n      <th>default </th>\n      <th>spiegazione </th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>spark.driver.cores</td>\n      <td>1</td>\n      <td>setta il numero di cores usati dal driver</td>\n    </tr>\n    <tr>\n      <td>spark.executor.cores</td>\n      <td>1 in modo YARN. Tutti i cores disponibili in modo Spark standalone e con Mesos </td>\n      <td>il numero di cores per ogni executor in fase di lancio del nodo</td>\n    </tr>\n    <tr>\n      <td>spark.task.cpu </td>\n      <td>1 </td>\n      <td>numero di task da allocare per ciascun core</td>\n    </tr>\n    <tr>\n      <td>spark.cores.max</td>\n      <td>non settato </td>\n      <td>il massimo numero di cores del cluster (totale, non per ogni executor) da assegnare <strong>all&rsquo;applicazione</strong>. Solo per Spark standalone e Mesos &ldquo;coarse-grained&rdquo; </td>\n    </tr>\n    <tr>\n      <td>spark.deploy.defaultCores</td>\n      <td>illimitato </td>\n      <td>numero default di cores del cluster da assegnare in Spark standalone se non è assegnato spark.cores.max. Si può usare per limitare il numero di cores da assegnare a diversi user di un cluster condiviso</td>\n    </tr>\n    <tr>\n      <td>spark.default.parallelism <br>sc.defaultParallelism</td>\n      <td>numero di cores??? </td>\n      <td>numero di default delle partizioni generate da operazioni quali <em>join</em> e <em>reduceByKey</em> e <em>parallelize</em></td>\n    </tr>\n  </tbody>\n</table>\n<h4>Esempio</h4>\n<p>Supponendo di essere in <strong>cluster mode</strong>, settando:<br/>- spark.cores.max = 5<br/>- spark.driver.cores = 1<br/>- spark.executor.cores = 2</p>\n<p>avrò un numero di executors pari a</p>\n<p>#executors = (spark.cores.max - spark.driver.cores)/spark.executor.cores = 2</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578177855986_699507766","id":"20200104-234415_320317775","dateCreated":"2020-01-04T23:44:15+0100","dateStarted":"2020-01-05T18:28:06+0100","dateFinished":"2020-01-05T18:28:06+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15843"},{"text":"%md\nRiferimenti\n1. [Spark Github](https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SparkContext.scala#L799)\n2. https://www.dezyre.com/article/how-data-partitioning-in-spark-helps-achieve-more-parallelism/297","user":"admin","dateUpdated":"2020-01-04T00:05:37+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Riferimenti<br/>1. <a href=\"https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SparkContext.scala#L799\">Spark Github</a><br/>2. <a href=\"https://www.dezyre.com/article/how-data-partitioning-in-spark-helps-achieve-more-parallelism/297\">https://www.dezyre.com/article/how-data-partitioning-in-spark-helps-achieve-more-parallelism/297</a></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1578075426332_-1224312992","id":"20191211-130043_314232691","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-04T00:05:37+0100","dateFinished":"2020-01-04T00:05:37+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15844"},{"text":"spark.conf.getAll.foreach(println)","user":"admin","dateUpdated":"2020-01-05T18:26:53+0100","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"results":{},"enabled":true,"editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"(spark.driver.host,LAPTOP-CD5FRQQG)\r\n(spark.driver.port,7778)\r\n(spark.jars,file:///C:/zeppelin-0.8.2-bin-all-local/interpreter/spark/spark-interpreter-0.8.2.jar,file:/C:/zeppelin-0.8.2-bin-all-local/interpreter/spark/spark-interpreter-0.8.2.jar)\r\n(spark.app.name,Zeppelin)\r\n(spark.executor.instances,4)\r\n(spark.executor.id,driver)\r\n(spark.driver.extraJavaOptions, -Dfile.encoding=UTF-8 -Dzeppelin.log.file='C:\\zeppelin-0.8.2-bin-all-local\\logs\\zeppelin-interpreter-spark-Anto-LAPTOP-CD5FRQQG.log')\r\n(spark.submit.deployMode,client)\r\n(spark.master,local[4])\r\n(spark.repl.local.jars,file:///C:/zeppelin-0.8.2-bin-all-local/interpreter/spark/spark-interpreter-0.8.2.jar)\r\n(spark.app.id,local-1578244297950)\r\n"}]},"apps":[],"jobName":"paragraph_1578075426336_2004077205","id":"20191211-130103_1686291439","dateCreated":"2020-01-03T19:17:06+0100","dateStarted":"2020-01-05T18:26:53+0100","dateFinished":"2020-01-05T18:26:55+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:15845"},{"user":"admin","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1578133717486_-1556747155","id":"20200104-112837_2034204350","dateCreated":"2020-01-04T11:28:37+0100","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:15846"}],"name":"Partitions","id":"2EZ9JQNYW","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"simple","personalizedMode":"false"},"info":{}}